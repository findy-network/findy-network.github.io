<!doctype html><html lang=en class=no-js>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.91.2"><link rel=canonical type=text/html href=/blog/>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel="shortcut icon" href=/favicons/favicon.ico>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16>
<link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32>
<link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36>
<link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48>
<link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72>
<link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96>
<link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144>
<link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192>
<title>Findy Agency Blog | Findy Agency</title>
<meta name=description content="Findy Agency documentation"><meta property="og:title" content="Findy Agency Blog">
<meta property="og:description" content="Findy Agency documentation">
<meta property="og:type" content="website">
<meta property="og:url" content="/blog/"><meta property="og:site_name" content="Findy Agency">
<meta itemprop=name content="Findy Agency Blog">
<meta itemprop=description content="Findy Agency documentation"><meta name=twitter:card content="summary">
<meta name=twitter:title content="Findy Agency Blog">
<meta name=twitter:description content="Findy Agency documentation">
<link rel=preload href=/scss/main.min.77ad8086257c5b04aec72128f0eebde3c7c6696b921b68c53e5e0d3f187d0a84.css as=style>
<link href=/scss/main.min.77ad8086257c5b04aec72128f0eebde3c7c6696b921b68c53e5e0d3f187d0a84.css rel=stylesheet integrity>
<script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
</head>
<body class="td-section td-blog">
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
<a class=navbar-brand href=/>
<span class=navbar-logo></span><span class="text-uppercase font-weight-bold">Findy Agency</span>
</a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class=nav-link href=/docs/><span>Documentation</span></a>
</li>
<li class="nav-item mr-4 mb-2 mb-lg-0">
<a class="nav-link active" href=/blog/><span class=active>Blog</span></a>
</li>
</ul>
</div>
<div class="navbar-nav d-none d-lg-block">
</div>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
</div>
<div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
</div>
<main class="col-12 col-md-9 col-xl-8 pl-md-5 pr-md-4" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.
</p><p>
<a href=/blog/>Return to the regular view of this page</a>.
</p>
</div>
<h1 class=title>Findy Agency Blog</h1>
<ul>
<li><a href=#pg-84fb4537e4edf11be52eda416e8de901>Fostering Interoperability</a></li>
<li><a href=#pg-1d28bc35aa6447c9e2cde89f9bd1b9f3>Anchoring Chains of Trust</a></li>
<li><a href=#pg-01f27610185446a311586be6588425a0>The Arm Adventure on Docker</a></li>
<li><a href=#pg-9a796d898f4a78defc54c95df256f75b>Travelogue</a></li>
<li><a href=#pg-cb63dd4f3907bf281fd73b19c6270088>Announcing Findy Agency</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-84fb4537e4edf11be52eda416e8de901>Fostering Interoperability</h1>
<div class=lead>Hyperledger Aries defines messaging protocols for identity agents capable of sharing verified data. Throughout Findy Agency development, the support for the Aries protocol and the compatibility with other Aries agents has been one of the top priorities for the project. Lately, we have lifted the interoperability testing to a new level by automating the testing and reporting with the help of tools provided by the Aries community. Furthermore, we received promising results from practical interoperability tests executed manually.</div>
<div class="td-byline mb-4">
By <b>Laura Vuorenoja</b> |
<time datetime=2022-01-19 class=text-muted>Wednesday, January 19, 2022</time>
</div>
<p>Different services have different requirements and technical stacks; there are also multiple ways to implement the Aries agent support in an application. Some projects choose to rely on an Aries framework of a specific language and bundle the functionality within the service. Others might run the agent as a separate service or, as in the case of Findy Agency, as an agency that serves multiple clients.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px>
<img class=card-img-top src=/blog/2022/01/19/fostering-interoperability/manual-test_hu2ad66fb4e4e3677b9f68960c3b1b7d49_90636_925x925_fit_catmullrom_3.png width=925 height=486>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Sending Aries basic messages between wallets from different technology stacks. See full demo in <a href="https://www.youtube.com/watch?v=W1H7ppS2Y6M" target=_blank rel="noopener noreferer">YouTube</a>.</em>
</p>
</div>
</div>
<p>Interoperability is a crucial element when we think about the adaptation and success of the Aries protocol. Even though the agent software might fulfill all the functional requirements and pass testing with use cases executed with a single agent technology stack, the story ending might be different when running the cases against another agent implementation. How can we then ensure that the two agents built with varying technology stacks can still work together and reach the same goals? Interoperability testing solves this problem. Its purpose is to verify that the agent software complies with the Aries protocol used to communicate between agents.</p>
<h2 id=aries-interoperability-testing>Aries Interoperability Testing</h2>
<p>Interoperability considerations came along quite early to the protocol work of the Aries community. The community faced similar challenges as other technical protocol developers have faced over time. When the number of Aries protocols increases and the protocol flows and messages are updated as the protocols evolve, how can the agent developers maintain compatibility with other agent implementations? The community decided to take <a href=https://github.com/hyperledger/aries-rfcs/tree/main/concepts/0302-aries-interop-profile>Aries Interoperability Profiles (AIPs)</a> in use. Each AIP version defines a list of <a href=https://github.com/hyperledger/aries-rfcs>Aries RFCs</a> with specific versions. Every agent implementation states which AIP version it supports and expects other implementations with the same version support to be compatible.</p>
<p>To ensure compatibility, the community had <a href=https://github.com/hyperledger/aries-rfcs/tree/main/concepts/0270-interop-test-suite>an idea of a test suite</a> that the agent developers could use to make sure that the agent supports the defined AIP version. The test suite would launch the agent software and run a test set that measures if the agent under test behaves as the specific protocol version requires. The test suite would generate a report of the test run, and anyone could then easily compare the interoperability results of different agents.</p>
<p>At first, there were two competing test suites with different approaches to execute the tests. <a href=https://github.com/hyperledger/aries-protocol-test-suite>Aries Protocol Test Suite (APTS)</a> includes an agent implementation that interacts with the tested agent through the protocol messages. On the other hand, <a href=https://github.com/hyperledger/aries-agent-test-harness>Aries Agent Test Harness (AATH)</a> runs the tests operating the agent-client interface. This approach makes it possible to measure the compatibility of any two agent implementations. AATH seems to be the winning horse of the test suite race. Its test suite includes several test cases and has extensive reporting in place.</p>
<h3 id=aries-agent-test-harness>Aries Agent Test Harness</h3>
<p>Aries Agent Test Harness provides a BDD (behavioral driven) test execution engine and a set of tests derived from Aries RFCs. The aim is to run these tests regularly between different Aries agents (and agent frameworks) to monitor the compatibility score for each combination and catch compatibility issues.</p>
<p>Harness operates the agents under test through backchannels. Backchannel is a REST interface defined by <a href=https://github.com/hyperledger/aries-agent-test-harness/blob/main/docs/assets/openapi-spec.yml>an OpenAPI definition</a>, and its purpose is to pass the harness requests to the agents. The target is to handle the agent as a black box without interfering with the agent&rsquo;s internal structures. Thus, the backchannel uses the agent&rsquo;s client interface to pass on the harness requests.</p>
<figure>
<img src=https://courses.edx.org/assets/courseware/v1/571727dd6d3f57d64158c9567f0d8ff2/asset-v1:LinuxFoundationX+LFS173x+1T2020+type@asset+block/The_Aries_Agent_Test_Harness.png> <figcaption>
<p>
<a href=https://learning.edx.org/course/course-v1:LinuxFoundationX+LFS173x+1T2020/home>image source: LinuxFoundationX LFS173x (CC BY 4.0)</a></p>
</figcaption>
</figure>
<p>Harness utilizes Docker containers for testing. It launches a container based on a required agent image for each test scenario actor during the test run. Before the test run, one needs to build a single image containing all the needed agent services and the backchannel. The recipes for making each of the different agent images, i.e., Dockerfiles with the needed scripts, are stored in the AATH repository. The same repository also contains CI scripts for executing the tests regularly and generating <a href=https://aries-interop.info/>an extensive test report site</a>.</p>
<h2 id=interoperability-for-findy-agency>Interoperability for Findy Agency</h2>
<p>One of our main themes for 2H/2021 was to verify the Aries interoperability level for Findy Agency. When I investigated the Aries interoperability tooling more, it became evident that we needed to utilize the AATH to accomplish the satisfactory test automation level.</p>
<p>My first task was to create <a href=https://github.com/findy-network/findy-agent-backchannel>a backchannel</a> for the harness to operate Findy Agency-hosted agents. Backchannel&rsquo;s role is to convert the harness&rsquo;s REST API requests to Findy Agency gRPC client interface. Another challenge was to combine the agency microservices into <a href=https://github.com/findy-network/findy-agent-backchannel/blob/master/aath/Dockerfile>a single Docker image</a>. Each agency microservice runs in its dedicated container in a regular agency deployment. For AATH, I needed to bundle all of the required services into a single container, together with the backchannel.</p>
<p>Once the bundle was ready, I made <a href=https://github.com/hyperledger/aries-agent-test-harness/pull/341>a PR to the AATH repository</a> to include Findy Agency in the Aries interoperability test set. We decided to support AIP version 1.0, but leave out the revocation for now. Tests exposed some essential but mainly minor interoperability issues with our implementation, and we were able to solve all of the found problems quite swiftly. The tests use the latest Findy Agency release with each test run. One can monitor <a href=https://aries-interop.info/findy.html>the test results for Findy Agency</a> on the test result site.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:949px>
<img class=card-img-top src=/blog/2022/01/19/fostering-interoperability/results_hufa4ee9cabbf5b53022a6b7fed8ad758e_125699_939x649_fit_catmullrom_3.png width=939 height=644>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Test result snapshot from <a href=https://aries-interop.info/ target=_blank rel="noopener noreferer">Aries test reporting site</a></em>
</p>
</div>
</div>
<p>In addition to interoperability testing, we currently utilize the AATH tooling for our functional acceptance testing. Whenever PR gets merged to our agency core repository that hosts the code for Aries protocol handlers, <a href=https://github.com/findy-network/findy-agent/blob/master/.github/workflows/iop.yml>CI builds</a> an image of the code snapshot and runs a partial test set with AATH. The testing does not work as a replacement for unit tests but more as a last acceptance gate. The agency core runs in the actual deployment Docker container. The intention is to verify both the successful agency bootup and the functionality of the primary protocol handlers. This testing step has proven to be an excellent addition to our test repertoire.</p>
<h3 id=manual-tests>Manual Tests</h3>
<p>Once the interoperability test automation reached an acceptable level, my focus moved to actual use cases that I could execute between the different agents.</p>
<p>My main interests were two wallet applications freely available in the app stores, <a href=https://lissi.id/>Lissi Wallet</a> and <a href=https://trinsic.id/trinsic-wallet/>Trinsic Wallet</a>. I was intrigued by how Findy Agency-based applications would work with these identity wallets. I also wanted to test our Findy Agency web wallet with an application from a different technology stack. <a href=https://github.com/bcgov>BCGov</a> provides a freely available test network that both wallet applications support, so it was possible to execute the tests without network-related hassle.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px>
<img class=card-img-top src=/blog/2022/01/19/fostering-interoperability/cover-demo.drawio_huf36e1a42bdf7cc78eb70fb813ee7e03b_414690_925x925_fit_catmullrom_3.png width=925 height=537>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Manual test setup</em>
</p>
</div>
</div>
<p>I executed the following tests:</p>
<ul>
<li>
<p><strong>Test 1: Findy Agency based issuer/verifier with Lissi Wallet</strong></p>
<p>A Findy Agency utilizing <a href=https://github.com/findy-network/findy-issuer-tool>issuer tool</a> invites Lissi Wallet to form a pairwise connection. Issuer tool sends and verifies a credential with Lissi Wallet.</p>
</li>
<li>
<p><strong>Test 2: Findy Agency Web Wallet with Trinsic Wallet</strong></p>
<p>Findy Agency Web Wallet user forms a pairwise connection with Trinsic Wallet user. Wallet applications send Aries basic messages to each other.</p>
</li>
<li>
<p><strong>Test 3: ACA-Py based issuer/verifier with Findy Agency Web Wallet</strong></p>
<p>Aries Test Harness runs <a href=https://github.com/hyperledger/aries-cloudagent-python>ACA-Py</a>-based agents that issue and verify credentials with Findy Agency Web Wallet.</p>
</li>
</ul>
<p>The practical interoperability of Findy Agency also seems to be good, as proven with these manual tests. You can find the video of the test screen recording on <a href="https://www.youtube.com/watch?v=W1H7ppS2Y6M">YouTube</a>.</p>
<div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden>
<iframe src=https://www.youtube.com/embed/W1H7ppS2Y6M style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe>
</div>
<h2 id=next-steps>Next Steps</h2>
<p>Without a doubt, Aries interoperability will be one of the drivers guiding the development of Findy Agency also in the future. With the current test harness integration, the work towards AIP2.0 is now easier to verify. Our team will continue working with the most critical Aries features relevant to our use cases. We also welcome contributions from others who see the benefit in building an OS world-class enterprise-level identity agency.</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-1d28bc35aa6447c9e2cde89f9bd1b9f3>Anchoring Chains of Trust</h1>
<div class=lead>Everything is about chains in asymmetric cryptography, or more precisely about <em>the links in the chain</em>. You build these links with public/private key pairs. The chain needs grounding, and the FIDO2 authenticator is perfect for that purpose.</div>
<div class="td-byline mb-4">
By <b>Harri Lainio</b> |
<time datetime=2021-11-09 class=text-muted>Tuesday, November 09, 2021</time>
</div>
<p>You will notice a repetitive pattern once you start to play with <a href=https://en.wikipedia.org/wiki/Public-key_cryptography>public-key cryptography</a>. Everything is about chains, or more
precisely about <em>the links in the chain</em>. You build these links with
public/private key pairs. Links are unidirectional, which means that if you must
link or point both ways, you need to have two key pairs, one for each
direction.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:601px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/RootOfChainWithAuthenticator_hud95e60c4b93d4f99683425572d5ff616_352781_591x0_resize_catmullrom_3.png width=591 height=344>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Crypto Chain with Authenticator</em>
</p>
</div>
</div>
<p>In this blog post, we talk mostly about protocols built with asymmetric key pairs,
but we can build immutable data structures like Merkle trees and blockchains with
<a href=https://en.wikipedia.org/wiki/One-way_function>one-way functions</a> as well. We
will return to these data types in future posts by building something
interesting to replace general ledgers as DID&rsquo;s
<a href=https://www.w3.org/TR/did-imp-guide/#verifiable-data-registry>VDR</a>.</p>
<h2 id=crypto-chain-protocols>Crypto Chain Protocols</h2>
<p>We all know that the connection protocols should cover all security
issues, but protocols based on public-key cryptography might not be so
obvious <em>public</em> key, you know? There are known subjects with protocols based on
asymmetric cryptography like
<a href=https://en.wikipedia.org/wiki/Trust_on_first_use>trust-on-first-use</a>.</p>
<img src=https://upload.wikimedia.org/wikipedia/commons/e/e7/Man_in_the_middle_attack.svg width=400 height=10>
<p align=center> MITM - <a href=https://upload.wikimedia.org/wikipedia/commons/e/e7/Man_in_the_middle_attack.svg>Wikipedia</a></p>
<p>It&rsquo;s trivial to execute <a href=https://en.wikipedia.org/wiki/Man-in-the-middle_attack>MITM</a>
attack if we cannot be sure that the public key source is the one it
should be. The industry has developed different ways to make sure that presented
details are valid. That lays down one of the most fundamental aspects of modern
cryptographic systems &ndash; <a href=https://en.wikipedia.org/wiki/Chain_of_trust>chain of
trust</a>.</p>
<p><img src=https://upload.wikimedia.org/wikipedia/commons/0/02/Chain_Of_Trust.svg alt="Trust Chain"></p>
<p align=center> PKI Chain of trust - <a href=https://upload.wikimedia.org/wikipedia/commons/0/02/Chain_Of_Trust.svg>Wikipedia</a></p>
<p>It is essential to understand that most of the modern security protocols use
public-key cryptography only for
<a href=https://en.wikipedia.org/wiki/Authentication>authentication</a> and switch to
<a href=https://en.wikipedia.org/wiki/Symmetric-key_algorithm>symmetric keys</a> during
the data transfer for performance reasons. The famous example of this kind of
protocol is <a href=https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange>Diffie-Hellman</a>
where the shared secret (the symmetric key) is transported over public network.</p>
<p>The <a href=https://github.com/hyperledger/aries-rfcs/blob/main/concepts/0005-didcomm/README.md>DIDComm</a>
protocol is something that is not used only for authentication but
communication without sacrificing privacy. My prediction is that the current
message-oriented DIDComm protocol as a holistic transport layer is not enough.
The ongoing <a href=https://github.com/decentralized-identity/didcomm-messaging>DIDComm
V2</a> mentions
potential other protocols like DIDComm Stream, DIDComm Multicast, and so forth,
but that will not be an easy task because of the current routing model, and
especially because of the privacy needs. That has been one reason we have
focused our efforts on finding a solution that would scale for all modern needs
of transporting data and keeping individuals private. For that, our cloud agency
is a perfect candidate.</p>
<h2 id=symmetry-vs-asymmetry-in-protocols>Symmetry vs Asymmetry in Protocols</h2>
<p>Before we go any further with DIDComm, let&rsquo;s think about what it means to have
an asymmetric protocol. We know the differences between symmetric and asymmetric
cryptography. Let&rsquo;s focus on communication, i.e. how we transport keys during
the protocol.</p>
<p>Asymmetric protocol means that Bob can trust Alice when Alice
have given her public key to Bob, and Bob can be sure that it&rsquo;s Alice whose key
he has received.</p>
<p>Every time Bob needs to authenticate Alice, he asks Alice to sign
something with her private key. To make it crystal-clear, cryptographically, we
can be only sure that it&rsquo;s Alice who (still) controls the private key.</p>
<p>We could achieve symmetry only by that Alice has Bob&rsquo;s public key as well. Now
Alice can ask Bob to sign something for the authenticity of Bob.</p>
<p>Why is this important? There are several reasons for that, but the most crucial
reason is <strong>the root-of-trust model</strong>. <em>The last link in the crypto chain
doesn&rsquo;t need to be bidirectional</em>, because <em>the last private key is the
cryptographic root-of-trust, i.e. it&rsquo;s passive</em>. It doesn&rsquo;t need authentication
from the referrer. It&rsquo;s like grounding in electronics.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:601px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/FirstChain_hud3a6f47a3b24ec8a1164faa8f7d21f8f_322561_591x0_resize_catmullrom_3.png width=591 height=335>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Crypto Chain with Grounding</em>
</p>
</div>
</div>
<h2 id=did-concepts>DID Concepts</h2>
<p>The DID&rsquo;s controller is an essential piece of the puzzle. It defines
who is the entity in the analogue world, i.e. who owns the DID cryptographically.
As long as we stay in a digital world, it is easiest to bind the controller to
its DID is by using public-key cryptography. The one who has DID controller&rsquo;s
private key is the actual controller.</p>
<p>For instance, an essential thing for SSI is <em>a DID pairwise</em>, i.e. a secure
connection between two DIDs or <a href=https://www.w3.org/TR/did-core/#dfn-service>DID
services</a>. Unfortunately, W3C&rsquo;s
specifications don&rsquo;t underline that enough. Probably because it concentrates on
external properties of DIDs and how the presented specification can implement
different methods. But DIDs cannot work on their own properly. They need to have
a controller, and in Aries, they have agents as well. Also, DIDs doesn&rsquo;t always
present the entity they are pointing, should I say, alone. DIDs present a
<em>subject</em>. A subject like an IoT device can have many different DIDs for many
different contexts.</p>
<p><img src=https://www.w3.org/TR/did-core/diagrams/did_brief_architecture_overview.svg alt="DID Concepts"></p>
<p align=center> DID Concepts - <a href=https://www.w3.org/TR/did-core/diagrams/did_brief_architecture_overview.svg>www.w3.org</a></p>
<p>In the digital world, it is expected that a controller has its controller, which
has its controller, etc. When public-key cryptography is used to verify this
controlling structure, it&rsquo;s a chain with its root, the final private key, i.e.
<em>the root-of-trust</em>.</p>
<h2 id=didcomm-protocols>DIDComm Protocols</h2>
<p>The following drawing describes a common installation scenario where an agency
based DID controller (leftmost) is implemented as verifiable automata (Finite
State Machine) and it&rsquo;s controlling the DID in the agency. At the right, there
is conventional Edge Agent running in a mobile device that needs a mediator to
help the agent is accessible from the network.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1001px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/BaseArchitecture_hu7901b95f6d30b4426ee2fd9a43a69eb4_499659_991x0_resize_catmullrom_3.png width=991 height=406>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>DIDComm Installation Example</em>
</p>
</div>
</div>
<p>As we can see in the drawing below, there are many different crypto chains in
the current installation. During the study, we were most interested in the
question: what is the best way to implement the root-of-trust for the DID
managed by the multi-tenant agency. Now we have found the answer. Luckily it
existed already.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1001px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/FullArchitecture_hu4b865196eaf2233c1035106d36ae8f15_921984_991x0_resize_catmullrom_3.png width=991 height=657>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>DIDComm Installation Example and Crypto Chain</em>
</p>
</div>
</div>
<h2 id=fido2-authentication>FIDO2 Authentication</h2>
<p>When we started to understand that the DIDComm protocol chain is not symmetric
to all directions. Or, more precisely, when we understood that there must be one
core agent for each identity domain and from that core or root agent, you should
refer to multiple <strong>separated authenticators</strong>.</p>
<p>Let&rsquo;s see what it means to have separate authenticators. The following drawing
illustrates an oldish and problematic way of implementing, e.g. password
manager, DID controller, SSI Edge Agent, etc.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:501px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/PwdMgrStart_hu0f6a53f8c1ff5985fbc060f44873529a_328558_491x0_resize_catmullrom_3.png width=491 height=549>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Integrated Secure Enclave</em>
</p>
</div>
</div>
<p>That is how we first thought our edge agent implementation where the mobile
device&rsquo;s secure element was felt as a cryptographic root-of-trust for an
identity domain that can be individual, organization, etc. However, that leads
to many unnecessary problems in protocol implementation. Most importantly, to
which part of the end-to-end protocol we should implement the use cases like:</p>
<ul>
<li>I want to use my identity domain from iPhone, iPad, etc. same time.</li>
<li>I want to have a &lsquo;forget password&rsquo; -type recovery option (by doing nothing)</li>
<li>I want to handle my identity domain&rsquo;s keys easily. More precisely, I don&rsquo;t
want to know public-key cryptography is used under the hood</li>
<li>I want to have automatic backups and recovery</li>
</ul>
<p>If we think about the drawing above, it&rsquo;s easy to see that the presented use
cases aren&rsquo;t easy to implement secure way if you have integrated a secure
element to your agent in the same machine. In case you have only one integrated
secure enclave for each edge agent, it&rsquo;s near impossible.</p>
<p>When we separate the secure enclave from the identity domain&rsquo;s root controller
at the design level, everything seems to be set in a place as we can see in the
next drawing.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1001px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/PwdMgrFull_hu4232b9d9afbfe01e455d6f477f2365d3_1060150_991x0_resize_catmullrom_3.png width=991 height=665>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Separated Secure Enclaves in Multiple Authenticators</em>
</p>
</div>
</div>
<p>I don&rsquo;t imply that all of the other parties in the SSI/DID study scene have done
or are making the same mistake we did at the beginning. My point is that
treating secure elements as the root of the crypto chain only and not
integrating it into the software agent or the device agent is running guided us
in the right direction. That allowed us to realize that we don&rsquo;t need a fully
symmetric protocol to bind the controller to the agent. All we needed was the
simplest possible thing, an authenticator, <strong>a trust anchor</strong> in all potential
cases.</p>
<p>That innovation brought us a possibility to use modern existing solutions and
still have an equally robust system where we have cryptographic root-of-rust.</p>
<p>It&rsquo;s essential to understand why we had to consider this so carefully. Should
it be just obvious? We must remember what kind of technology we were
developing. We didn&rsquo;t want to make a mistake that would lead back to
centralization. For example, if we would still totally relay
<a href=https://en.wikipedia.org/wiki/Public_key_infrastructure>PKI</a>, which is
centralized, we couldn&rsquo;t do that.</p>
<p>During the years we have studied the SSI/DID technology, we have constantly
tested the architecture with these questions:</p>
<ol>
<li>Could this work and be safe without any help from the current PKI? (Naturally,
it doesn&rsquo;t mean that we couldn&rsquo;t use individual protocols like TLS, etc. The
infrastructure is the keyword here.)</li>
<li>Can a use case or a protocol action be executed peer to peer, i.e.
between only two parties? (Doesn&rsquo;t still necessarily mean off-line)</li>
</ol>
<h2 id=headless-fido2webauthn-authenticator>Headless FIDO2/WebAuthn Authenticator</h2>
<blockquote>
<p>FIDO2 is the name of the standard. WebAuthn is just browser JS API to talk to
the authenticators. So correct way to call your server is &ldquo;FIDO2 Server&rdquo; and
to say &ldquo;Authentication with FIDO2&rdquo;. -
<a href=https://github.com/herrjemand/awesome-webauthn#faq>WebAuthn Resource List</a></p>
</blockquote>
<p>We started our tests with the new agent API by using implementing our <em>FIDO2
server</em> and by using only browsers at the beginning. When results, especially
the performance and simplicity, were so good, we decided to go further.</p>
<p>The following architecture-drawing present the final deployment diagram of the
overall system. The needed FIDO2 components are marked light red, and the ones
we implemented ourselves are marked in red.</p>
<p>The basic idea was to have a system-level SSO where we implemented authorization
with JWT and authentication with FIDO2 regardless of which type of the entity
needs to be authenticated: individuals, organizations, legal entities, or system
components. For us, it implicated that we needed FIDO2 for service agents, which
meant that a <em>headless</em> FIDO2 Authenticator was required.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1601px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/DeploymentArchitecture_hu35f0112cd83673eb5666a9c53975c3bf_2052432_1591x0_resize_catmullrom_3.png width=1591 height=867>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>All Key Components of The System Architecture</em>
</p>
</div>
</div>
<p>Architectural requirements for the solution were quite complex because we wanted
to have security covered, not to compromise performance, and still support
polyglot development.</p>
<h2 id=polyglot-authenticator-interface>Polyglot Authenticator Interface</h2>
<p>FIDO2/WebAuthn specification gives a well over a description of how main
components work. Here we focus on the two most important ones. The first is the
authenticator registration flow which is presented picture below.</p>
<p><img src=https://www.w3.org/TR/webauthn/images/webauthn-registration-flow-01.svg alt="WebAuthn Registration"></p>
<p align=center> FIDO2 Authenticator Registration - <a href=https://www.w3.org/TR/webauthn/images/webauthn-registration-flow-01.svg>www.w3.org</a></p>
<p>To summarise, the above flow registers a new instance of an authenticator. Then
it verifies that the same authenticator is bound to the account. That is done
using a unique public/private key pair where the private key is in the
authenticator. Note that the authenticator doesn&rsquo;t map a particular user to an
account. That is done thru the other process flow and by the <a href=https://www.w3.org/TR/webauthn/#webauthn-relying-party>relying
party</a>.</p>
<p>The flow below shows how a registered authenticator is used to authenticate the
account holder.</p>
<p><img src=https://www.w3.org/TR/webauthn/images/webauthn-authentication-flow-01.svg alt="WebAuthn Authentication"></p>
<p align=center> FIDO2 Authentication - <a href=https://www.w3.org/TR/webauthn/images/webauthn-authentication-flow-01.svg>www.w3.org</a></p>
<p>The Command pattern was the perfect solution for the first authenticator
implementation because it supported all of our use cases, but same time was
simplest. Most straightforward to integration was naturally with a programming
language it was implemented which was Go.</p>
<p>The second thing was to figure out how we would like to implement interprocess
communication. For that, the command pattern is suited very well. Fill the
command with all the needed data and give one of the operations we were
supporting: <code>register</code> and <code>login</code> from the FIDO2 standard. The process
communication is handled just as the process starts by reading the command from
JSON. That is suited for Node.js use as well. (For the record, my fantastic
colleague Laura did all the needed Node.js work.)</p>
<p>When we considered security, we followed our post-compromise principle. We
didn&rsquo;t (yet) try to solve the situation where someone managed to hack the server
and hook a debugger to our processes without our notice. To solve that, we need
<a href=https://en.wikipedia.org/wiki/Trusted_execution_environment>TEE</a> or similar.
Our specification is ready, but before the implementation, we should think if
it&rsquo;s worth it, and about the use case we are implementing.</p>
<h3 id=stateless-authenticator>Stateless Authenticator</h3>
<p>Because you rarely find anything that removes complexity from your
implementation from security-related standards or specifications, it&rsquo;s forth of
mentioning: By following <a href=https://www.w3.org/TR/webauthn/>WebAuthn
specification</a> I did learn that I could, once
again, use crypto chaining!</p>
<p>We knew that you would use one authenticator for many different places. That was
clear, of course. But when an authenticator is used for the service or as a
service, there is the next tenancy level.</p>
<p>Before I started to write the whole thing, I thought that I use our server-side
secure enclave to store all the key pairs there and let the tenant set the
enclave&rsquo;s master key. It would still mean that the implementation would be
state-full. From the operations' perspective, we all know what that means: more
things to take care of and manage, but most importantly, one potential
scalability issue to solve.</p>
<p>The FIDO2 standard documentation describes a perfect solution for our needs
which made our authenticator stateless. You give the other party your public
key, but you give your private key in your <code>credential ID</code>. It might
first sound crazy, but it&rsquo;s genius indeed.</p>
<p>Hold on! That cannot be?</p>
<p>But it is. You have to build your identifier to include your private key, but no
one but you can use it because you have encrypted it with a symmetric master
key. The key that no one but you controls.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1301px>
<img class=card-img-top src=/blog/2021/11/09/anchoring-chains-of-trust/MasterKeyMain_hu010c6f71b85452493ec3cbb36ce48ca0_2698229_1291x0_resize_catmullrom_3.png width=1291 height=663>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Stateless Authenticator Implementation</em>
</p>
</div>
</div>
<p>The draft above illustrates how our stateless FIDO2 authenticator works at
a master key level. Other factors like a cloning counter and an authenticator ID
are left out for simplicity.</p>
<ol>
<li>We can ask TEE to create a new key pair for FIDO2 registration, which gives
us a unique key pair that includes <code>public key</code> and <em>encrypted private key</em>,
i.e. <code>credential ID</code>.</li>
<li>Our authenticator sends the FIDO2 <code>attestation object</code> to the server.</li>
<li>When the authenticator receives the FIDO2 challenge during authentication, it builds
it to the key pair in the same format as registration.</li>
<li>The TEE inside the authenticator builds us the <code>assertion object</code> ready to send
to the FIDO2 server.</li>
</ol>
<p>As we can see, the master key never leaves the TEE. The implementation can
be done with help cloud
<a href=https://en.wikipedia.org/wiki/Hardware_security_module>HSM</a> or
<a href=https://www.neclab.eu/research-areas/security/nec-labs-introduce-a-new-solution-enables-seamless-provisioning-and-decommissioning-of-tee-based-applications-in-the-cloud>TEE-based app</a>;
or we can implement an application with the help of <a href=https://aws.amazon.com/ec2/nitro/nitro-enclaves/>AWS
Nitro Enclaves</a> or similar.</p>
<p><strong>Note!</strong> This is not a good solution for a pure client-side <em>software-based</em>
authenticator, because it needs help from the hardware, i.e. secure enclave.
It&rsquo;s suitable for <em>hardware-based and certain types of server-side solutions</em>
where you can use TEE or similar solutions.</p>
<h2 id=conclusion>Conclusion</h2>
<p>FIDO2 authentication is an excellent match for DID Wallet authentication. gRPC
transport combined with JWT authorization has been straightforward to use. Our
gRPC SDK allows you to implicitly move the JWT token during the API calls after
opening the server connection. Plus, gRPC&rsquo;s capability to have bidirectional
streams make the programming experience very pleasant. Finally, an option is to
authenticate the gRPC connection between server and client with (no PKI is
needed) TLS certificates: You can authorize software components to bind to your
deployment.</p>
<p>The SDK and the API we have built with this stack have fulfilled all our
expectations:</p>
<ul>
<li>security</li>
<li>performance</li>
<li>easy to use</li>
<li>solving <a href=https://en.wikipedia.org/wiki/Don%27t_repeat_yourself>DRY</a> e.g.
error handling</li>
<li>polyglot</li>
<li>cloud-ready</li>
<li>micro-service friendly</li>
</ul>
<p>And hopefully yours. Give it a try!</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-01f27610185446a311586be6588425a0>The Arm Adventure on Docker</h1>
<div class=lead>Since the Findy Agency project launched, Docker has been one of our main tools to help set up the agency development and deployment environments. An unexpected headache developed when our colleague purchased an M1 Mac, and our images refused to run on the ARM platform.</div>
<div class="td-byline mb-4">
By <b>Laura Vuorenoja</b> |
<time datetime=2021-09-20 class=text-muted>Monday, September 20, 2021</time>
</div>
<p>Since the Findy Agency project launched, Docker has been one of our main tools to help set up the agency development and deployment environments. First of all, we use Docker images for our cloud deployment. On a new release, the CI build pipeline bundles all needed binaries to each service image. After the build, the pipeline pushes Docker images to <a href=https://github.blog/2020-09-01-introducing-github-container-registry/>the GitHub container registry</a>, from where the deployment pipeline fetches them and updates the cloud environment.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:706px>
<img class=card-img-top src=/blog/2021/09/20/the-arm-adventure-on-docker/cover-agency-deployment-pipeline_hu45c26a180b4a9f8ed9e980905a894a35_52542_925x925_fit_catmullrom_3.png width=696 height=385>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Agency deployment pipeline: New release triggers image build in GitHub actions. When the new container image is in the registry, AWS Code Pipelines handles the deployment environment update.</em>
</p>
</div>
</div>
<p>In addition, we’ve used Docker to take care of the service orchestration in a local development environment. When developing the agency itself, a native setup with full debugging capabilities is naturally our primary choice. However, suppose one wishes only to use the agency services and develop, e.g., a web service utilizing agency capabilities. In that case, the most straightforward approach is to run agency containers with a preconfigured docker-compose script. The script pulls correct images to the local desktop and sets needed configuration parameters. Setting up and updating the three services could be cumbersome without the orchestration, at least for newbies.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:635px>
<img class=card-img-top src=/blog/2021/09/20/the-arm-adventure-on-docker/arch-overview_hud3b603a9121f1582ad6844475842d5cd_90814_625x625_fit_catmullrom_3.png width=625 height=546>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>High-level architecture of Findy Agency. Setting up the agency to localhost is most straightforward with the help of a container orchestration tool.</em>
</p>
</div>
</div>
<p>Until recently, we were happy with our image-building pipeline. Local environments booted up with ease, and the deployment pipeline rolled out updates beautifully. Then one day, our colleague with an M1-equipped Mac tried out the docker-compose script. Running the agency images in an Arm-based architecture was something we hadn&rsquo;t considered. We built our Docker images for amd64 architecture, while M1 Macs expect container images for arm64 CPU architecture. It became clear we needed to support also the arm64, as we knew that the popularity of the M1 chipped computers would only increase in the future.</p>
<h2 id=multi-architecture-support-in-docker>Multi-architecture Support in Docker</h2>
<p>Typically, when building images for Docker, the image inherits the architecture type from the building machine. And as each processor architecture requires a dedicated Docker image, one needs to build a different container image for each target architecture. To avoid the hassle with the multiple images, Docker has added support for multi-architecture images. It means that there is a single image in the registry, but it can have many variants. Docker will automatically choose the appropriate architecture for the processor and platform in question and pull the correct variant.</p>
<p>Ok, so Docker takes care of the image selection when running images. How about building them then? There are <a href=https://docs.docker.com/buildx/working-with-buildx/#build-multi-platform-images>three strategies</a>.</p>
<ol>
<li><strong>QEMU emulation support in the kernel</strong>: QEMU works by emulating all instructions of a foreign CPU instruction set on the host processor. For example, it can emulate ARM CPU instructions on an x86 host machine, and thus, the QEMU emulator enables building images that target another architecture than the host. This approach usually requires the fewest modifications to the existing Dockerfiles, but the build time is the slowest.</li>
<li><strong>Multiple native nodes using the same builder instance</strong>: Hosts with different CPU architectures execute the build. The build time is faster than with the other two alternatives. The drawback is that it requires access to as many native nodes as there are target architectures.</li>
<li><strong>Stage in a Dockerfile for cross-compilation</strong>: This option is possible with languages that support cross-compilation. Arguments exposing the build and the target platforms are automatically available to the build stage. The build command can utilize these parameters to build the binary for the correct target. The drawback is that the builder needs to modify the Dockerfile build commands and perhaps familiarize oneself with using the cross-compilation tools for the target language.</li>
</ol>
<p>From these three options, we chose the first one, as it seemed the most straightforward route. However, in our case, the third option might have worked as well since we are building with tools that support cross-compilation, Rust, and GoLang.</p>
<p>A Docker CLI plugin, <a href=https://docs.docker.com/buildx/working-with-buildx/>buildx</a>, is required to build multi-architecture images. It extends the docker command with additional features, the multi-architecture build capability being one of them. Using buildx is almost the same as using the ordinary Docker build function. The target platform is added to the command with the flag <code>--platform</code>.</p>
<p>Example of building Docker image with buildx for arm64:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>docker buildx build --platform linux/arm64 -t image_label .
</code></pre></div><h2 id=reviewing-the-build-receipts>Reviewing the Build Receipts</h2>
<p>Now we had chosen the strategy and had the tools installed. The next step was to review each image stack and ensure that it was possible to build all image layers for the needed variants.</p>
<p>Our default image stack consists of <a href=https://github.com/findy-network/findy-common-go/blob/master/infra/aws/Dockerfile.indy.ubuntu>the custom base image</a> and an application layer (service binary in question). The custom base image contains some tools and libraries that are common for all of our services. It expands the official Docker image for Ubuntu.</p>
<p>For the official Docker images, there are no problems since Docker provides the needed variants out-of-the-shelf. However, our custom base image installs indy-sdk libraries from the Sovrin Debian repository, and unfortunately, the Debian repository did not provide binaries for arm64. So instead of installing the library from the Debian repository, we needed to add <a href=https://github.com/findy-network/findy-common-go/blob/8bef1cbc4cc7d698275a69a9c9c4aff2622b84de/infra/aws/Dockerfile.indy.ubuntu#L12>a build step</a> that would build and install the indy-sdk from the sources. Otherwise, building for arm64 revealed no problems.</p>
<h2 id=integration-to-github-actions>Integration to GitHub Actions</h2>
<p>The final step was to modify our GitHub Actions pipelines to build the images for the different architectures. Fortunately, Docker provides ready-made actions for setting up QEMU (<em><a href=https://github.com/docker/setup-qemu-action>setup-qemu-action</a></em>) and buildx (<em><a href=https://github.com/docker/setup-buildx-action>setup-buildx-action</a></em>), logging to the Docker registry (<em><a href=https://github.com/docker/login-action>login-action</a></em>), and building and pushing the ready images to the registry (<em><a href=https://github.com/docker/build-push-action>build-push-action</a></em>).</p>
<p>We utilized the actions provided by Docker, and <a href=https://github.com/findy-network/findy-agent/blob/master/.github/workflows/release.yml>the release workflow</a> for findy-agent looks now like this:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yml data-lang=yml><span style=color:#204a87;font-weight:700>name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>release</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>on</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>  
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>push</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>tags</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#4e9a06>&#39;*&#39;</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>jobs</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>push-image</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>runs-on</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>ubuntu-latest</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>permissions</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>packages</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>write</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>contents</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>read</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>steps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#204a87;font-weight:700>uses</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>actions/checkout@v2</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#204a87;font-weight:700>name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Set up QEMU</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>uses</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>docker/setup-qemu-action@v1</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>with</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>platforms</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>all</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#204a87;font-weight:700>name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Set up Docker Buildx</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>uses</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>docker/setup-buildx-action@v1</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#204a87;font-weight:700>name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Login to Registry</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>uses</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>docker/login-action@v1</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>with</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>registry</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>ghcr.io</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>username</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>${{ github.repository_owner }}</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>password</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>${{ secrets.GITHUB_TOKEN }}</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#204a87;font-weight:700>run</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>echo &#34;version=$(cat ./VERSION)&#34; &gt;&gt; $GITHUB_ENV</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>      </span>- <span style=color:#204a87;font-weight:700>uses</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>docker/build-push-action@v2</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>with</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>platforms</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>linux/amd64,linux/arm64</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>push</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>tags</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>|</span><span style=color:#8f5902;font-style:italic>
</span><span style=color:#8f5902;font-style:italic>            ghcr.io/${{ github.repository_owner }}/findy-agent:${{ env.version }}
</span><span style=color:#8f5902;font-style:italic>            ghcr.io/${{ github.repository_owner }}/findy-agent:latest</span><span style=color:#f8f8f8;text-decoration:underline>            
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>cache-from</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>type=registry,ref=ghcr.io/${{ github.repository_owner }}/findy-agent:latest</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>cache-to</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>type=inline</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>          </span><span style=color:#204a87;font-weight:700>file</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>./scripts/deploy/Dockerfile</span><span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>The result was as expected; the actions took care of building of the container images successfully. The build process is considerably slower with QEMU, but luckily, the build caches speed up the process.</p>
<p>Now have the needed variants for our service images in the registry. Furthermore, our colleague with the M1-Mac can run the agency successfully with his desktop.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px>
<img class=card-img-top src=/blog/2021/09/20/the-arm-adventure-on-docker/findy-agent-packages_huee06773afc479fec8fbdb4f9dc73d730_149630_925x925_fit_catmullrom_3.png width=925 height=483>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em><a href=https://github.com/findy-network/findy-agent/pkgs/container/findy-agent>Docker registry</a> for Findy agent</em>
</p>
</div>
</div>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-9a796d898f4a78defc54c95df256f75b>Travelogue</h1>
<div class=lead>We have used many different techniques, technologies and architectures to build a modern and high-performance DID agency. During the journey we have not only been able to learn SSI essentials but also <em>align modern software and hardware technologies best suited for decentralized identity network</em>.</div>
<div class="td-byline mb-4">
By <b>Harri Lainio</b> |
<time datetime=2021-09-08 class=text-muted>Wednesday, September 08, 2021</time>
</div>
<p>The success of our team is measured:</p>
<ul>
<li>How well do we understand <em>certain</em> emerging technologies?</li>
<li>How relevant they are to the business we are in?</li>
<li>How much potential do they have for our company&rsquo;s business?</li>
</ul>
<p>If you are asking yourself if the order of the list is wrong, the answer is, it
is not.</p>
<p>We have learned that you will fail if you prioritize technologies by their
business value too early. There is a catch, though. You must be sure that you
will not fall in love with the technologies you are studying. Certain scepticism
is welcomed in our line of work. That attitude may follow thru this post as
well. You have now been warned, at least.</p>
<h3 id=technology-tree>Technology Tree</h3>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2001px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/TechTree_hucb3e947ff7ac3c644fea522c44e98b42_1584631_1991x0_resize_catmullrom_3.png width=1991 height=1120>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Findy Agency Tech Tree</em>
</p>
</div>
</div>
<p>Technology roots present the most important <em>background knowledge</em> of our study.
The most fundamental technologies and study subjects are in the trunk. The
trunk is the backbone of our work. It ties it all together. Branches and leaves
are outcomes, conclusions, and key learnings. At the top of the tree, some
future topics are considered but not implemented or even tried yet.</p>
<p>Even if the technology tree illustrates the relevant technologies for the
subject, we will not address them in this post. <strong>We recommend you to study the
tree for a moment</strong> to get the picture. You will notice that there aren&rsquo;t any
mention of VC. For us, the concept of VC is an internal feature of
<a href=https://www.w3.org/TR/vc-data-model/>DID system</a>. Naturally, there are a huge
amount of enormous study subjects inside VCs like ZKP, etc. But this approach
has to lead us to concentrate on the network itself and the structure it should
have.</p>
<p>The tree has helped us to see how things are bound together and what topics are
the most relevant for the study area.</p>
<h3 id=trust-triangle>Trust Triangle</h3>
<p>The famous SSI trust triangle is an excellent tool to simplify what is
important and what is not. As we can see, everything builds on peer to peer
connections, thick arrows. VCs are issued, and proofs are presented thru them.
The only thing that&rsquo;s not yet solved <em>at the technology level</em> is the trust
arrow in the triangle. (I know the recursive trust triangle, but I disagree with
how it&rsquo;s thought to be implemented). But <em>this blog post</em> is not about that
either.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:605px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/trust-triangle_hua2e42792a9d20037c5f572b0412e67c1_57626_925x925_fit_catmullrom_3.png width=595 height=392>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>The SSI Trust Triangle</em>
</p>
</div>
</div>
<h3 id=targets-and-goals>Targets and Goals</h3>
<p>Every project&rsquo;s objectives and goals change during the execution. The longer the
project, the more pivots it has. (Note that I use the term <em>project</em> quite
freely in the post). When we started to work with DID/SSI field, the goal was to
build <strong>a standalone mobile app demo</strong> of the identity wallet based on
Hyperledger Indy. We started in <em>test drive mode</em> but built a full DID agency
and published it as OSS. The journey has been inspiring, and we have learned a
lot.</p>
<p>In every project, it&rsquo;s important to maintain the scope. Thanks to the nature of
our organisation we didn&rsquo;t have changing requirements. The widening of the scope
came mostly from the fact that the whole area of SSI and DID were evolving. It
still is.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/targets_hu3c26761ab0ee4aee9c5a7a0b4088e778_867526_925x925_fit_catmullrom_3.png width=925 height=520>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>The Journey From Identity Wallet to Identity Ecosystem</em>
</p>
</div>
</div>
<p>Many project goals changed significantly during the execution, but that was part
of the job. And as DID/SSI matured, we matured as well, and goals to our work
aren&rsquo;t <em>so</em> <em>test-driven</em> mode anymore. We still test other related technologies
that can be matched to DID/SSI or even replace some parts of it
but have transited to the state where we have started to build our own related
core technologies to the field.</p>
<p>Incubators usually start their trip by testing different hypotheses and trying
them out in practice. We did the same but more on the practical side. We didn&rsquo;t
have a formal hypothesis, but we had some use cases and a vision of how modern
architecture should work and its scaling requirements. Those kinds of
principles lead our <em>decision-making process</em> during the project.
(Maybe some of us write a detailed blog about how our emerging tech process and
organisation worked.)</p>
<h2 id=the-journey>The journey</h2>
<p>We have been building our multi-tenant agency since the beginning of 2019.
During that time, we have tried many different techniques, technologies and
architectures, and application metaphors. We think we have succeeded to find
interesting results.</p>
<p>In the following chapters, we will report the time period from the beginning of
2019 to autumn of 2021 in half of a year intervals. I really recommend that you
look at the timelines carefully because they include valuable outcomes.</p>
<h3 id=2019h1>2019/H1</h3>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2010px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/spring19_hu29db0a4a24cce1cc4a7a017360286d3b_559718_2000x0_resize_catmullrom_3.png width=2000 height=1125>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>2019/H1</em>
</p>
</div>
</div>
<h5 id=the-start>The Start</h5>
<p>Me:</p>
<blockquote>
<p>&ldquo;I&rsquo;m interested in studying new tech by programming with it.&rdquo;</p>
</blockquote>
<p>Some block-chain experts in the emerging technologies team:</p>
<blockquote>
<p>&ldquo;We need an identity wallet to be able to continue with our other projects.
Have you ever heard of Hyperledger Indy..&rdquo;</p>
</blockquote>
<p>In one week, I have been smoke-tested indy SDK on iOS and Linux. During the
spring, we ended up following the Indy&rsquo;s proprietary agent to agent
protocol, <strong>but</strong> we didn&rsquo;t use <em>libcvx</em> for that because:</p>
<blockquote>
<p>This library is currently in an <strong>experimental</strong> state and is not part of
official releases. - [indy SDK GitHub pages]</p>
</blockquote>
<p>To be honest, that was the most important reason because we have had so much
extra work with other Indy libs, and of course, we would need a wrapper at least for
Go. It was an easy decision. Afterwards, it was the right because the DIDComm
protocol is the backbone of everything with SSI/DID. And now, when it&rsquo;s in our
own (capable) hands, it&rsquo;s made many such things possible which weren&rsquo;t otherwise.
We will publish a whole new technical blog series of our multi-tenant DIDComm
protocol engine.</p>
<p>All of the modern, native mobile apps end up been written from two parts: the mobile
app component running on the device and the server part doing everything it can
to make the mobile app&rsquo;s life easier. Early stages, DIDComm&rsquo;s edge and cloud agent
roles weren&rsquo;t that straightforward. From every point of view, it seemed overly
complicated. But still, we stuck to it.</p>
<h5 id=first-results>First Results</h5>
<p>At the end of spring 2019, we had a quick and dirty demo of the system, which had
<strong>multi-tenant</strong> agency to serve cloud agents and iOS mobile app to run edge
agents. An EA onboarded itself to the agency with the same DID Connect
protocol, which was used everywhere. Actually, an EA and a CA
used Web Sockets as a transport mechanism for indy&rsquo;s DIDComm messages.</p>
<p>We hated the protocol. It was insane. But it was DID protocol, wasn&rsquo;t it?</p>
<p>The system was end to end encrypted, but the indy protocol had its flaws, like
being synchronous. We didn&rsquo;t yet have any persistent state machine or the other
basics of the communication protocol systems. Also, the whole thing felted
overly complicated and old &ndash; it wasn&rsquo;t modern cloud protocol.</p>
<h5 id=third-party-integration-demo>Third party integration demo</h5>
<p>In early summer ended up building a demo that didn&rsquo;t follow totally the current
architecture, because the mobile app&rsquo;s edge agent was communicating directly to
the third party agent. This gave us a lot of experience, and for me, it gave
needed time to spec what kind of protocol the DIDComm should be and what kind of
protocol engine should run it.</p>
<p>It was a weird time because indy&rsquo;s legacy agent to agent protocol didn&rsquo;t have a
public, structured and formal specification of its protocol.</p>
<p>Those who are interested in history can read more from
<a href=https://hyperledger-indy.readthedocs.io/projects/hipe/en/latest/text/0002-agents/README.html>here</a>.</p>
<p>The integration project made it pretty clear for us what kind of protocol was
needed.</p>
<blockquote>
<p><strong>Async with explicit state machine</strong></p>
</blockquote>
<p>DIDComm must be async and message-driven simple because it&rsquo;s deliberative in
its nature. Two agents are negotiating for issuing, proofing, etc.</p>
<h5 id=aries-news>Aries news</h5>
<p>Hyperledger Aries was set up during the summer, which was good because it showed
the same we learned. We were on the right path.</p>
<h5 id=code-delivery-for-a-business-partner>Code Delivery For a Business Partner</h5>
<p>For this mail-stone, we ended up producing some documentation, mostly to
explain the architecture. During the whole project, we have had a comprehensive
unit and integration test harness.</p>
<p>At this point, we had all of the important features covered: issuing, holding,
present and verify proofs in a quick and dirty way. Now we knew the potential.</p>
<h5 id=results-2019-summer>Results 2019 Summer</h5>
<p>We had managed to implement pre-Aries DIDComm over HTTP and WebSocket. We had
a multi-tenant agency running cloud agents even though it was far from
production readiness. Everything was end to end encrypted. The current agency
supported indy&rsquo;s ledger transactions, and first, we had taken some tests from
issuing and proofing protocols. We started to understand what kind of beast was
tearing at us from another end of the road.</p>
<h3 id=2019h2>2019/H2</h3>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2010px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/autumn19_hu29db0a4a24cce1cc4a7a017360286d3b_515478_2000x0_resize_catmullrom_3.png width=2000 height=1125>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>2019/H2</em>
</p>
</div>
</div>
<h5 id=start-of-the-async-protocol-development>Start Of The Async Protocol Development</h5>
<p>When we started architecture redesign after the summer break,
we had a clear idea of what kind of direction we should take and what to leave for
later:</p>
<ul>
<li><strong>Cloud-first</strong> and we have newer wanted to step back on that.</li>
<li><strong>Modern micro-service architecture</strong> targeting continuous delivery and
scalability. That leads to a certain type of technology stack which consists of
techs like Go, gRPC, Docker (or other containerization technology), container
orchestration like K8s, etc. One key requirement was that hardware utilization
must be perfect, i.e. tiny servers are enough.</li>
<li><strong>No support for offline</strong> use cases <em>for now</em>.</li>
<li><strong>No revocation</strong> until there is a working solution. Credit card revocation has
taught us a lot. Scalable and fast revocation is a hard problem to solve.</li>
<li>Message routing should not be part of the protocol&rsquo;s explicit &lsquo;headers&rsquo;, i.e.
there is <strong>only one service endpoint for a DID</strong>. We should naturally handle the
service endpoint so that privacy is maintained as it is in our agency. By
leaving routing out, it has been making everything so much simple. Some
technologies can do that for us for free, like Tor. We have tested Tor, and it
works pretty well for setting service endpoints and also connecting to them.</li>
<li><strong>Use push notifications along with the WebSockets</strong>, i.e. lent APNS to trigger
edge agents when they were not connected to the server.</li>
</ul>
<h5 id=multi-ledger-architecture>Multi-ledger Architecture</h5>
<p>Because everything goes through our Go wrapper to the Plenum ledger, I made a
version that used memory or plain file instead of the ledger as a hobby project.
It was meant to be used only for tests and development. Later the plug-in
architecture has allowed us to have other persistent saving media as well. But
more importantly, it has helped development and automatic testing a lot.</p>
<p>Technically the <em>hack</em> is to use <code>pool handle</code> to tell if the system is
connected to a ledger or some other predefined media. <code>indy</code> API has only two
functions that take <code>pool handle</code> as an argument but doesn&rsquo;t use it at all <em>or</em>
a handle is an option.</p>
<h5 id=server-side-secure-enclaves>Server Side Secure Enclaves</h5>
<p>During the server-side development, we wanted to have at least post-compromised
secured key storage for cloud servers. Cloud environments like AWS give you
managed storage for master secrets, but we needed more when developing OSS
solutions with high performance and scalability requirements.</p>
<p>Now we store our most important keys for LMDB-based fast key-value storage
fully encrypted. Master keys for installation are in a managed cloud environments
like AWS, Google, Azure, etc.</p>
<h5 id=first-multi-tenant-chat-bot>First Multi-tenant Chat Bot</h5>
<p>The first running version of the chatbot used a semi-hard-coded version.
It supported only sequential steps: a single line in a text file,
<code>CredDefIds</code> in its own file, and finally text messages in its own files. The
result was just a few lines of Go code, thanks to its concurrent model.</p>
<p>The result was so good that I made a backlog issue to start studying to
use SCXML or some other exciting language for chatbot state machines later.
About a year later, I implemented a state machine on my own with a proprietary YAML
format.</p>
<p>But that search isn&rsquo;t totally over. Before that, I considered many different
options, but there wasn&rsquo;t much of an OSS alternative. One option could be to
embed Lua combined with the current state machine engine and replace the memory
model with Lua. We shall see what the real use case needs are.</p>
<p>I personally think that an even more important approach would be <strong>a state machine
verifier</strong>. Keeping that as a goal sets strict limits to the computation
model we could use. What we have learned now is you don&rsquo;t need the full power of
general programming language but
<a href=https://en.wikipedia.org/wiki/Automata_theory>finite state machine (automata theory)</a>
could just be enough.</p>
<h4 id=2019h2-results>2019/H2 Results</h4>
<p>We had implemented all the most important use cases with our new protocol
engine. We had an symmetric agent which could be in all of the needed roles of SSI:
a holder, an issuer, and a verifier. Also, the API seemed to be OK at a high
level of abstraction. The individual messages were shit.</p>
<p>At the end of the year, we also had a decent toolbox both on command-line and
especially on the web.</p>
<h3 id=2020h1>2020/H1</h3>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2010px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/spring20_hu29db0a4a24cce1cc4a7a017360286d3b_486983_2000x0_resize_catmullrom_3.png width=2000 height=1125>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>2020/H1</em>
</p>
</div>
</div>
<h5 id=findy-consortium-level-oss-publication>Findy-consortium Level OSS Publication</h5>
<p>At the beginning of 2020, we decided to publish all the produced
code inside the Findy consortium. We produced the new GitHub account, and code
without history moved from original repos to new ones.</p>
<p>Even the decision brought a lot of routine work for that moment, it also brought
many good things:</p>
<ul>
<li>refactoring,</li>
<li>interface cleanups,</li>
<li>documentation updates.</li>
</ul>
<h5 id=aca-py-interoperability-tests>ACA-Py Interoperability Tests</h5>
<p>We implemented the first version of the new async protocol engine with existing
JSON messages came from legacy indy a2a protocols. It&rsquo;s mostly because I
wanted to build it in small steps, and it worked pretty well.</p>
<p>Most of the extra work did come from the legacy API we had. JSON messages over
indy&rsquo;s proprietary DIDComm. As always, some bad but some good: because we had to
keep both DIDComm message formats, I managed to integrate a clever way to
separate different formats and still generalise with Go&rsquo;s interfaces.</p>
<h5 id=new-cli>New CLI</h5>
<p>We noticed that Agency&rsquo;s command-line UI started to be too complicated. Go has
a clever idea of how you can do services without environmental variables. I&rsquo;m
still the guy who would stick with that, but it was a good idea to widen the
scope to make our tools comfortable for all new users.</p>
<p>Our design idea was to build CLI, which follows subcommands like git and docker
nowadays. The latest version we have now is quite good already, but the road was
rocky. It is not easy to find the right structure the first time. The more you
use your CLI by yourself, the more you start to notice what is intuitive and
what is not.</p>
<p>We decided to separate CLI commands from Agency to own tool and git repo. It was
good to move for that time, and when we managed to make it right, we were able to
move those same commands pack to the agency one year later because we needed CLI
tool without any <em>libindy</em> dependencies. That is a good example of successful
software architecture work. You cannot predict the future, but you can prepare
yourself for change.</p>
<h3 id=2020h2>2020/H2</h3>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2010px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/autumn20_hu29db0a4a24cce1cc4a7a017360286d3b_544015_2000x0_resize_catmullrom_3.png width=2000 height=1125>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>2020/H2</em>
</p>
</div>
</div>
<h5 id=architecture-planning>Architecture Planning</h5>
<p>I had had quite a long time the idea of using gRPC for the Cloud Agent
controller. My core idea was to get rid of the EA because, currently, it was
just an onboarding tool. The wallet had, included only the pairwise DID to its
cloud agent, nothing else. The actual wallet (we called it worker edge agent
wallet) was the real wallet, where the VCs were. I went thru
many similar protocols until I found FIDO UAF. The protocol is similar to
DIDComm&rsquo;s pairwise protocol, but it&rsquo;s not symmetric. Another end is the server,
and the other has the authenticator &ndash; the cryptographical root of
trust.</p>
<p>When I presented an internal demo of the gRPC with the JWT authorization and
explained that authentications would be FIDO2 WebAuthn, we were ready to start
the architecture transition. Everything was still good when I implemented the
first FIDO server with the help of Duo Labs Go packages. Our FIDO2 server was
now capable of allocating cloud agents. But there was one missing part I was
hoping someone in the OSS community would implement until we needed it. It was a
headless WebAuthn/UAF authenticator for those issuers/verifiers running as
service agents. How to onboard them, and how they would access the agency&rsquo;s
resources with the same JWT authorization? To allow us to proceed, we added
support to get JWT by our old API. It&rsquo;s was only intermediated solution but
served its purpose.</p>
<h5 id=learnings-when-implementing-the-new-architecture>Learnings when implementing the new architecture</h5>
<ul>
<li>implicit JWT authorization helps gRPC usage a lot and simplifies it too.</li>
<li>gRPC streams and Go&rsquo;s channel is just excellent together.</li>
<li>You should use pre-generated wallet keys for indy wallets.</li>
<li>We can integrate performance and scalability tests into CI.</li>
<li>gRPC integration and unit testing could be done in the same way as with HTTP
stack in Go, i.e. inside a single process that can play both client and server.</li>
</ul>
<h5 id=highlights-of-the-end-of-the-year-2020>Highlights of the end of the year 2020</h5>
<p>We started to build for new SA architecture and allowed both our APIs to
existing. WebAuth server, headless authenticator, and Vault first versions were
now ready. Also, I did the first version of a state machine for service agent
implementation. We had an option to use immuDB instead of Plenum ledger.</p>
<h3 id=2021h1>2021/H1</h3>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2010px>
<img class=card-img-top src=/blog/2021/09/08/travelogue/spring21_hu29db0a4a24cce1cc4a7a017360286d3b_511190_2000x0_resize_catmullrom_3.png width=2000 height=1125>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>2021/H1</em>
</p>
</div>
</div>
<p>Now we have an architecture that we can live with. All the important elements
are in place. Now we just clean it up.</p>
<h5 id=summary-of-spring-2021-results>Summary of Spring 2021 Results</h5>
<p>Until the summer, the most important results have been:</p>
<ul>
<li>Headless WebAuthn authenticator</li>
<li>React-based Web Wallet</li>
<li>Lots of documentation and examples</li>
<li>Agency&rsquo;s gRPC API v1</li>
<li>Polyglot implementations gRPC: TypeScript, Go, JavaScript</li>
<li>New toolbox both Web and Command-line</li>
<li>The full OSS release</li>
</ul>
<p>As said, all of the important elements are in place. However, our solution is
based on <code>libindy</code>, which will be interesting because the Aries group moves to
shared libraries, whereas the original contributor continues with it. We haven&rsquo;t
made the decision yet on which direction we will go. Or do we even need to
choose? At least in the meantime, we could add some new solutions and run them
both. Thanks to our own architecture and interfaces, those are plausible options
for our agency.</p>
<p>There are many interesting study subjects we are continuing to work on within
SSI/DID. We will report them in upcoming blog posts. Stay tuned, folks!</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-cb63dd4f3907bf281fd73b19c6270088>Announcing Findy Agency</h1>
<div class=lead>We, the Findy development team at OP Lab, are proud to present Findy Agency. Findy Agency is a collection of services and tools that makes building applications easier that rely on verified data exchange. Findy Agency has been published fully as open-source, so now anyone can start exploring and utilizing it.</div>
<div class="td-byline mb-4">
By <b>Laura Vuorenoja</b> |
<time datetime=2021-08-11 class=text-muted>Wednesday, August 11, 2021</time>
</div>
<p>Findy Agency provides a <a href=https://www.hyperledger.org/use/aries>Hyperledger Aries</a> compatible identity agent service. It includes a web wallet for individuals and an API for organizations to utilize functionality related to verified data exchange: issuing, holding, verifying, and proving credentials. The agents hosted by the agency operate using DIDComm messaging and <a href=https://github.com/hyperledger/aries-rfcs>Hyperledger Aries protocols</a>. Thus it is interoperable with other Hyperledger Aries compatible agents. The supported verified credential format is currently <a href=https://github.com/hyperledger/indy-sdk>Hyperledger Indy</a> “Anoncreds” that work with Hyperledger Indy distributed ledger. However, the plan is to add more credential formats in the future.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px>
<img class=card-img-top src=/blog/2021/08/11/announcing-findy-agency/vision_hu68846d3af499a7706e2100471d9aa9d5_34254_925x925_fit_catmullrom_3.png width=925 height=322>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>Main design principles of Findy Agency</em>
</p>
</div>
</div>
<p>In this post, we share some background information on the project. If you want to skip the history, start directly with <a href=/docs>the documentation</a> or <a href=https://github.com/findy-network/findy-wallet-pwa/tree/dev/tools/env#agency-setup-for-local-development>launch Findy Agency in your local computer</a>.</p>
<p><strong>Verified data exchange as digitalization enabler</strong></p>
<p>Distributed and self-sovereign identity, along with verified data exchange between different parties, has been an area of our interest at <a href=https://op-lab.fi/>the OP innovation unit</a> for quite some time. After all, when thinking about the next steps of digitalization, secure and privacy-preserving handling of identity is one of the main problem areas. When individuals and organizations can prove facts of themselves digitally, it will enable us to streamline and digitalize many processes that may be still cumbersome today, including those in the banking and insurance sectors.</p>
<p>Since 2019 the Findy team at OP has been working on two fronts. We have collaborated with other Finnish organizations to set up a cooperative to govern <a href=https://findy.fi/en/>a national identity network Findy</a>. At the same time, our developers have researched credential exchange technologies, concentrating heavily on Hyperledger Indy and Aries.</p>
<p><strong>From scratch to success with incremental cycles</strong></p>
<p>When we started the development at the beginning of 2019, the verified credential world looked a whole lot different. Low-level indy-sdk was all that a developer had if wanting to work with indy credentials. It contained basic credential manipulation functionality but almost nothing usable related to communication between individuals or organizations. We were puzzled because the scenarios we had in mind involved users with mobile applications and organizations with web services and interaction happening between these two.</p>
<p>Soon we realized that we needed to build all the missing components ourselves if we would want to do the experiments. And so, after multiple development cycles and as a result of these experiments became Findy Agency. The path to this publication has not always been straightforward: there have been complete refactorings and changes in the project direction along the way. However, we feel that now we have accomplished something that truly reflects our vision.</p>
<div class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px>
<img class=card-img-top src=/blog/2021/08/11/announcing-findy-agency/bot-scenario_hu15894898d496192ef1d77a0f852ae033_200283_925x925_fit_catmullrom_3.png width=925 height=520>
<div class="card-body px-0 pt-2 pb-0">
<p class=card-text>
<em>One of the team's experiments, Findy Bots, was built on Findy Agency. See demo video in <a href="https://www.youtube.com/watch?v=gVr8KwISMS4">Youtube</a>.</em>
</p>
</div>
</div>
<p><strong>Why the hard way?</strong></p>
<p>The situation is not anymore so sad for developers wanting to add credential support to their app as it was three years ago. There are several service providers and even <a href=https://github.com/hyperledger/aries#aries-agent-frameworks>open source solutions</a> one can choose from. So why did we choose the hard way and wrote an agency of our own? There are several reasons.</p>
<ul>
<li><strong>Experience</strong>: We believe that verified data technology will transform the internet in a profound way. It will have an impact on perhaps even the most important data processing systems in our society. We want to understand the technology thoroughly so that we know what we are betting on.</li>
<li><strong>Open-source</strong>: As we stated in the previous bullet, we want to be able to read and understand the software we are running. In addition, community-given feedback and contributions improve the software quality. There is also a good chance that open-sourced software is more secure than proprietary since it has more eyes looking at the possible security flaws.</li>
<li><strong>Pragmatic approach</strong>: We have scarce resources, so we have to concentrate on the most essential use cases. We do not wish to bloat the software with features that are far in the future if valid at all.</li>
<li><strong>Performance</strong>: We aim to write performant software with the right tools for the job. We also value developer performance and hence have a special eye for the quality of the API.</li>
</ul>
<p><strong>The Vision</strong></p>
<p>Our solution contains several features that make our vision and that we feel most of other open-source solutions are missing.</p>
<p>Findy Agency has been <strong>multi-tenant</strong> from the beginning of the project. It means single agency installation can securely serve multiple individuals and organizations without extra hassle.</p>
<p>Agency architecture is based on <strong>a cloud strategy</strong>. Credential data is stored securely in the cloud and cloud agents do all the credentials-related hard work on behalf of the agency users (wallet application/API users). The reasoning for the cloud strategy is that we think that individuals store their credential data rather with a confided service provider than worry about losing their device or setting up complex backup processes. Furthermore, the use cases relevant to us are also always executed online, so we have knowingly left out the logic aiming for offline scenarios. This enabled us to reduce the complexity related to mediator implementation.</p>
<p>Due to the cloud strategy, we could drop out the requirement for the mobile application. Individuals can use <strong>the web wallet</strong> with their device browser. Authentication to the web wallet is done with secure and passwordless <strong><a href=https://webauthn.guide/>WebAuthn/FIDO protocol</a></strong>.</p>
<p>Agency backend services are implemented with <strong>performance</strong> in mind. That is why we selected performant <a href=https://golang.org/>GoLang</a> and <a href=https://grpc.io/>gRPC</a> as the base technologies of the project.</p>
<p><strong>Next steps</strong></p>
<p>We do not regard Findy Agency as a finalized product, there is still a lot to be done. However, we think it can already be used to experiment and build verified data utilizing scenarios. Our work continues with further use case implementations as well as improving the agency with selected features based on our experimentation results.</p>
<p>The codes are available in <a href=https://github.com/findy-network>GitHub</a> and <a href=/docs>the developer documentation</a> will be improved in the near future. We look forward getting feedback from the community.</p>
</div>
</main>
</div>
</div>
<footer class="bg-dark py-5 row d-print-none">
<div class="container-fluid mx-sm-5">
<div class=row>
<div class="col-6 col-sm-4 text-xs-center order-sm-2">
</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank rel=noopener href=https://github.com/findy-network aria-label=GitHub>
<i class="fab fa-github"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
<small class=text-white>&copy; 2022 The Findy Agency Authors All Rights Reserved</small>
<p class=mt-2><a href=/about/>About Findy Agency</a></p>
</div>
</div>
</div>
</footer>
</div>
<script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script>
<script src=/js/main.min.5c74b870c6953931a705f390a49c7e4c0a842ec5c83b24354758dd674343ed0d.js integrity="sha256-XHS4cMaVOTGnBfOQpJx+TAqELsXIOyQ1R1jdZ0ND7Q0=" crossorigin=anonymous></script>
</body>
</html>